library(readr)
library(dplyr)
library(lubridate)
library(tidyverse)
LA <- read.csv("C:/Users/dance/Desktop/Spring 22/BUMK746/LA_Listings3.csv") summary(LA)

#clean data
#transfer variables to factors LA$Street <- as.factor(LA$Street)
LA$City <- as.factor(LA$City)
LA$Amenities <-as.factor(LA$Amenities)
LA$Property_type<- as.factor(LA$Property_type)
LA$Room_type<- as.factor(LA$Room_type)
LA$Country<- as.factor(LA$Country)
LA$State<- as.factor(LA$State)
LA$Neighbourhood_cleansed<- as.factor(LA$Neighbourhood_cleansed) 

#format the date 
LA$Calendar_last_scraped<-mdy(LA$Calendar_last_scraped) 
LA$Last_Review_Date <-mdy(LA$Last_Review_Date)
summary(LA)

#Dummy coded
LA$Host_Is_Superhost <- ifelse(LA$Host_Is_Superhost == "TRUE", 1,0)

#Create new variables
LA$Is_Apartment <- ifelse(LA$Property_type=="Apartment",1,0)
LA$Is_House <- ifelse(LA$Property_type=="House",1,0)
LA$condo <- ifelse(LA$Property_type=="Condominium",1,0)
LA$Townhouse <- ifelse(LA$Property_type=="Townhouse",1,0)
LA$Loft<- ifelse(LA$Property_type=="Loft",1,0)
LA$Guesthouse<- ifelse(LA$Property_type=="Guesthouse",1,0)
LA$entirehouse <- ifelse(LA$Room_type=="Entire home/apt",1,0)
LA$privateroom <- ifelse(LA$Room_type=="Private room",1,0)
LA$sharedroom <- ifelse(LA$Room_type=="Shared room",1,0)
LA$Hollywood_Neighbourhood <- ifelse(LA$Neighbourhood_cleansed=="Hollywood",1,0)
LA$Venice_Neighbourhood <- ifelse(LA$Neighbourhood_cleansed=="Venice",1,0) 
LA$LongBeach_Neighbourhood <- ifelse(LA$Neighbourhood_cleansed=="Long Beach",1,0) 
LA$Downtown_Neighbourhood <- ifelse(LA$Neighbourhood_cleansed=="Downtown",1,0) 
LA$SantaMonica_Neighbourhood <- ifelse(LA$Neighbourhood_cleansed=="Santa Monica",1,0) 
LA$Recent_Review <-ifelse(is.na(LA$Last_Review_Date),as.Date("2020-12-31")-as.Date("2017-04-30"),as.Date("2020-1 2-31")-LA$Last_Review_Date)

#exploratory data and remove outliner
summary(LA) LA<-LA[LA$Number_of_reviews!=0&LA$Review_Scores_Rating!=0,]
boxplot(LA$Review_Scores_Rating) 
boxplot(LA$Host_total_listings_count) 
boxplot(LA$Price) boxplot(LA$Recent_Review) 
boxplot(LA$Number_of_reviews) 
boxplot(LA$Minimum_nights) 
boxplot(LA$Reviews_per_month)
quantile(LA$Review_Scores_Rating, probs = c(0.01)) 
LA<-LA[LA$Review_Scores_Rating>=60,]
quantile(LA$Host_total_listings_count, probs = c(0.99), na.rm = T) 
LA<-LA[LA$Host_total_listings_count<=36,]
quantile(LA$Price, probs = c(0.99), na.rm = T) 
LA<-LA[LA$Price<=650,]
quantile(LA$Recent_Review, probs = c(0.99),na.rm = T) 
LA<-LA[LA$Recent_Review<=2189.19,]
quantile(LA$Number_of_reviews, probs = c(0.99),na.rm = T) 
LA<-LA[LA$Number_of_reviews<=201,]
quantile(LA$Minimum_nights, probs = c(0.99),na.rm = T) 
LA<-LA[LA$Minimum_nights<=30,]
quantile(LA$Reviews_per_month, probs = c(0.99),na.rm = T) 
LA<-LA[LA$Reviews_per_month<=8.33,]

#transfer NA into mean/median of the variables
LA$Host_Response_Rate <- ifelse(is.na(LA$Host_Response_Rate), mean(LA$Host_Response_Rate,na.rm=TRUE),LA$Host_Response_Rate) 
LA$Host_total_listings_count <- ifelse(is.na(LA$Host_total_listings_count), median(LA$Host_total_listings_count,na.rm=TRUE),LA$Host_total_listings_count) 
LA$Accommodates <-ifelse(is.na(LA$Accommodates), median(LA$Accommodates,na.rm=TRUE),LA$Accommodates)
LA$Bathrooms <-ifelse(is.na(LA$Bathrooms), median(LA$Bathrooms,na.rm=TRUE),LA$Bathrooms)
LA$Bedrooms <-ifelse(is.na(LA$Bedrooms), median(LA$Bedrooms,na.rm=TRUE),LA$Bedrooms) 
LA$Maximum_nights <-ifelse(is.na(LA$Maximum_nights), median(LA$Maximum_nights,na.rm=TRUE),LA$Maximum_nights)

#drop some NA
LA<- LA %>% drop_na(Neighbourhood_cleansed)
summary(LA)

#number of columns after splitting by space, find 10-15% amenities Amenities<-data.frame(LA$Amenities)
colnames(Amenities)
install.packages('splitstackshape')
library(splitstackshape) Amenities_2<-cSplit(Amenities, "LA.Amenities", ";")
colnames(Amenities_2)
Amenities_3<-Amenities_2 %>% gather(col,amenities,LA.Amenities_01:LA.Amenities_45,na.rm = T)
Amenities_3$amenities<-tolower(Amenities_3$amenities)
Amenities_3<-Amenities_3 %>% count(amenities) Amenities_3<-Amenities_3[order(Amenities_3$n,decreasing = T),]
head(Amenities_3)

#find "24-hour check-in", "indoor fireplace", "lock on bedroom door", "pool", "elevator in building" in the LA dataset amenities
Amenities_list = c("24-hour check-in", "indoor fireplace", "lock on bedroom door", "pool", "elevator in building")
for (i in 1:length(Amenities_list)){ LA[Amenities_list[i]]<-ifelse(grepl(Amenities_list[i],LA$Amenities,ignore.case = TRUE),1,0)
}
head(LA)

#create a subset for modeling 
LA_sample<-LA[,c("Host_Response_Rate","Host_Is_Superhost","Host_total_listings_count","Acco mmodates","Bathrooms","Bedrooms","Price","Minimum_nights","Maximum_nights","Availability_3 65",
"Number_of_reviews","Review_Scores_Rating","Review_Scores_Accuracy",
"Review_Scores_Cleanliness","Review_Scores_Checkin","Review_Scores_Communication","Revie w_Scores_Location",
"Review_Scores_Value","Reviews_per_month","Is_Apartment","Is_House","condo","Townhouse","L oft","Guesthouse",
"Hollywood_Neighbourhood","Venice_Neighbourhood","LongBeach_Neighbourhood","Downtown_ Neighbourhood","SantaMonica_Neighbourhood",
"entirehouse","privateroom","sharedroom","Recent_Review","24-hour check-in", "indoor fireplace", "lock on bedroom door", "pool", "elevator in building")]
summary(LA_sample)

#turn blank into _
library(janitor) 
LA_sample<-clean_names(LA_sample)
write.csv(LA_sample, "LA_sample.csv",row.names = FALSE)
#Set training and testing dataset
library(caret)
set.seed(13343)
train_ind <- createDataPartition(y = LA_sample$review_scores_rating,p=.8,list = FALSE) 
training <- LA_sample[train_ind,]
test <- LA_sample[-train_ind,] 
summary(test)

#see correlation and check collinearity colnames(training)
summary(training) 
training_t<-training
training_t[] <- lapply(training_t, as.numeric) 
correlation<-data.frame(cor(training_t))

#delete "review_scores_cleanliness","bedrooms","review_scores_accuracy","is_house" 
training<-training[,-which(names(training) %in% c( "review_scores_accuracy","review_scores_cleanliness","bedrooms","is_house"))] test<-test[,-which(names(test) %in% c( "review_scores_accuracy","review_scores_cleanliness","bedrooms","is_house"))] 
colnames(training)

#variable selection using Forward-stepwise regression
library(lars)
y = training$review_scores_rating
x = training[,-which(names(training)%in%"review_scores_rating")] x_t<-as.matrix(x)
res = lars(x_t, y, type="stepwise") print(summary(res))
res

#cp=24.223 26 variables included, which are "review_scores_value", 'review_scores_communication', #host_is_superhost', 'host_total_listings_count', 'price',
#'number_of_reviews', 'privateroom', 'accommodates', 'is_apartment', 'review_scores_checkin', 'minimum_nights', 'lock_on_bedroom_door',
#'host_response_rate', 'pool', 'availability_365', 'maximum_nights', 'hollywood_neighbourhood', 'loft', #'bathrooms', 'review_scores_location', 
'recent_review', 'reviews_per_month','guesthouse','santa_monica_neighbourhood', #'venice_neighbourhood','elevator_in_building'

#add review_scores_rating also. total 27 variables
training<-training[,c("review_scores_rating","review_scores_value", 'review_scores_communication', 'host_is_superhost', 'host_total_listings_count', 'price',
'number_of_reviews', 'privateroom', 'accommodates', 'is_apartment', 'review_scores_checkin', 'minimum_nights', 'lock_on_bedroom_door', 'host_response_rate', 
'pool', 'availability_365', 'maximum_nights', 'hollywood_neighbourhood', 'loft', 'bathrooms', 'review_scores_location', 'recent_review', 'reviews_per_month', 
'guesthouse', 'santa_monica_neighbourhood', 'venice_neighbourhood','elevator_in_building')]

test <- test[,c("review_scores_rating","review_scores_value", 'review_scores_communication', 'host_is_superhost', 'host_total_listings_count', 'price',
'number_of_reviews', 'privateroom', 'accommodates', 'is_apartment', 'review_scores_checkin', 'minimum_nights', 'lock_on_bedroom_door', 
'host_response_rate', 'pool', 'availability_365', 'maximum_nights', 'hollywood_neighbourhood', 'loft','bathrooms', 'review_scores_location', 
'recent_review', 'reviews_per_month', 'guesthouse', 'santa_monica_neighbourhood', 'venice_neighbourhood', 'elevator_in_building')]

#knn
#training X &Y
#check where's the location of review_scores_rating colnames(training)
colnames(test)

train_x = training[, -1] train_x = scale(train_x)[,] train_y = training[,1] 
#test X &Y
test_x = test[, -1]
test_x = scale(test[,-1])[,] test_y = test[,1]

#knn model test
knnmodel = knnreg(train_x, train_y)
#predict
pred_y = predict(knnmodel, data.frame(test_x))

print(data.frame(test_y, pred_y)) R2(pred_y,test_y,form="traditional") 
mse = mean((test_y - pred_y)^2) 
mae = caret::MAE(test_y, pred_y) 
rmse = caret::RMSE(test_y, pred_y)
cat("MSE: ", mse, "MAE: ", mae, " RMSE: ", rmse)

x = 1:length(test_y)
plot(x[1:50], test_y[1:50], col = "red", type = "l", lwd=2,
main = "knn regression: test data prediction")
lines(x, pred_y, col = "blue", lwd=2) 
legend("bottomright", legend = c("original", "predicted"),fill = c("red", "blue"), col = 2:3, adj = c(0, 0.6)) 
grid()
#############################################################
#train
knnmodel = knnreg(train_x, train_y)
#predict
pred_y = predict(knnmodel, data.frame(train_x))
print(data.frame(train_y, pred_y))
R2(pred_y,train_y,form="traditional")
mse = mean((train_y - pred_y)^2)
mae = caret::MAE(train_y, pred_y)
rmse = caret::RMSE(train_y, pred_y)

cat("MSE: ", mse, "MAE: ", mae, " RMSE: ", rmse)

x = 1:length(train_y)
plot(x[1:50], train_y[1:50], col = "red", type = "l", lwd=2,
     main = "knn regression: train data prediction")
lines(x, pred_y, col = "blue", lwd=2)
legend("bottomright",  legend = c("original", "predicted"), 
       fill = c("red", "blue"), col = 2:3,  adj = c(0, 0.6))
grid() 


linear regression

#######################
#Scaling the features##
#######################

scaled_train = training
scaled_test = test

#only the predictors
cols = c("review_scores_value", 'review_scores_communication',
         'host_is_superhost', 'host_total_listings_count', 'price',
         'number_of_reviews', 'privateroom', 'accommodates', 'is_apartment', 'review_scores_checkin', 'minimum_nights', 'lock_on_bedroom_door',
         'host_response_rate', 'pool', 'availability_365', 'maximum_nights', 'hollywood_neighbourhood', 'loft',
         'bathrooms', 'review_scores_location', 'recent_review', 'reviews_per_month','guesthouse','santa_monica_neighbourhood',
         'venice_neighbourhood','elevator_in_building')


pre_proc_val <- preProcess(scaled_train[,cols], method = c("center", "scale"))

scaled_train[,cols] = predict(pre_proc_val, scaled_train[,cols])
scaled_test[,cols] = predict(pre_proc_val, scaled_test[,cols])

summary(scaled_train)

###############################
#standard multiple regression## 
###############################

lr = lm(review_scores_rating ~ review_scores_value + review_scores_communication + host_is_superhost +
        host_total_listings_count + price+number_of_reviews + privateroom + accommodates +
        is_apartment + review_scores_checkin+minimum_nights+ lock_on_bedroom_door +
        host_response_rate + pool + availability_365 + maximum_nights + hollywood_neighbourhood +
        loft + bathrooms + review_scores_location + recent_review + reviews_per_month + guesthouse +
        santa_monica_neighbourhood + venice_neighbourhood + elevator_in_building, data = scaled_train)
          
summary(lr)

#Evaluation : Type 1
reg_pred = predict(lr, newdata = scaled_train)

MAE(reg_pred,training$review_scores_rating)
mse(reg_pred,training$review_scores_rating)
rmse(reg_pred,training$review_scores_rating)

#Evaluation : Type 2
#Step 1 - creating the evaluation metrics function
eval_metrics = function(model, df, predictions, target){
  resids = df[,target] - predictions
  resids2 = resids**2
  N = length(predictions)
  r2 = as.character(round(summary(model)$r.squared, 2))
  adj_r2 = as.character(round(summary(model)$adj.r.squared, 2))
  print(adj_r2) #Adjusted R-squared
  print(as.character(round(sqrt(sum(resids2)/N), 2))) #RMSE
}

# Step 2 - predicting and evaluating the model on train data
predictions = predict(lr, newdata = scaled_train)
eval_metrics(lr, scaled_train, predictions, target = 'review_scores_rating')

# 0.44
# 4.98

# TRAINING
# Multiple R-squared:  0.4432,
# Adjusted R-squared:  0.4424
# MAE 3.161168
# MSE 24.78808
# RMSE 4.978763/ 4.98
# The above output shows that RMSE, one of the two evaluation metrics,
# is 4.98 for training data. On the other hand, R-squared value is around
# 44% for training data which indicates average performance.


#Test
cl = training$review_scores_rating
cl_test = test$review_scores_rating

res2 = lm(review_scores_rating ~ review_scores_value + review_scores_communication + host_is_superhost +
            host_total_listings_count + price+number_of_reviews + privateroom + accommodates +
            is_apartment + review_scores_checkin+minimum_nights+ lock_on_bedroom_door +
            host_response_rate + pool + availability_365 + maximum_nights + hollywood_neighbourhood +
            loft + bathrooms + review_scores_location + recent_review + reviews_per_month + guesthouse +
            santa_monica_neighbourhood + venice_neighbourhood + elevator_in_building, data = scaled_test)

summary(res2)

#Evaluation : Type 1
reg_pred2 = predict(res2, newdata = scaled_test)

MAE(reg_pred2,test$review_scores_rating)
mse(reg_pred2,test$review_scores_rating)
rmse(reg_pred2,test$review_scores_rating)

#Evaluation : Type 2
#Step 1 - creating the evaluation metrics function
eval_metrics = function(model, df, predictions, target){
  resids = df[,target] - predictions
  resids2 = resids**2
  N = length(predictions)
  r2 = as.character(round(summary(model)$r.squared, 2))
  adj_r2 = as.character(round(summary(model)$adj.r.squared, 2))
  print(adj_r2) #Adjusted R-squared
  print(as.character(round(sqrt(sum(resids2)/N), 2))) #RMSE
}

# Step 2 - predicting and evaluating the model on test data
predictions = predict(lr, newdata = scaled_test)
eval_metrics(lr, scaled_test, predictions, target = 'review_scores_rating')

# "0.44"
# "5.13"

#The above output shows that RMSE, one of the two evaluation metrics,
#is 5.13 for test data. On the other hand, R-squared value is around 
# 44 % for test data which indicates average performance also lower than the training data.

#Test 
# Multiple R-squared:  0.4251
# Adjusted R-squared:  0.4217 
# MAE 3.220544
# MSE 26.12188
# RMSE 5.110957/ 5.13


##Regularization##  

cols_reg = c('review_scores_rating','review_scores_value', 'review_scores_communication',
              'host_is_superhost', 'host_total_listings_count', 'price',
              'number_of_reviews', 'privateroom', 'accommodates', 'is_apartment',
              'review_scores_checkin', 'minimum_nights', 'lock_on_bedroom_door',
              'host_response_rate', 'pool', 'availability_365', 'maximum_nights',
              'hollywood_neighbourhood', 'loft','bathrooms', 'review_scores_location',
              'recent_review', 'reviews_per_month','guesthouse','santa_monica_neighbourhood',
              'venice_neighbourhood','elevator_in_building')

dummies <- dummyVars(review_scores_rating ~ ., data = LA_sample[,cols_reg])

train_dummies = predict(dummies, newdata = training[,cols_reg])

test_dummies = predict(dummies, newdata = test[,cols_reg])

print(dim(train_dummies)); print(dim(test_dummies))

#######################
###Ridge Regression ### 
#######################

library(glmnet)
library(MASS)

cl = training$review_scores_rating
cl_test = test$review_scores_rating

x = as.matrix(train_dummies)
y_train = cl

x_test = as.matrix(test_dummies)
y_test = cl_test

lambdas <- 10^seq(2, -3, by = -.1)
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = lambdas)

summary(ridge_reg)

coef(ridge_reg)
plot(ridge_reg)

cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda


# Compute R^2 from true and predicted values
eval_results <- function(true, predicted, df) {
  SSE <- sum((predicted - true)^2)
  SST <- sum((true - mean(true))^2)
  R_square <- 1 - SSE / SST
  RMSE = sqrt(SSE/nrow(df))
  
  
  # Model performance metrics
  data.frame(
    RMSE = RMSE,
    Rsquare = R_square
  )  
}


# Prediction and evaluation on train data
predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x)
eval_results(y_train, predictions_train, scaled_train)
R2(predictions_train,scaled_train$review_scores_rating)


# Prediction and evaluation on test data
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test)
eval_results(y_test, predictions_test, scaled_test)
R2(predictions_test,scaled_test$review_scores_rating)


#TRAINING
# RMSE   
# 6.284161
# Rsquare
# 0.396136

# TEST
# RMSE 
#6.35103
# 0.3710907


#######################
###Lasso Regression ### 
#######################
x = as.matrix(train_dummies)
y_train = cl

x_test = as.matrix(test_dummies)
y_test = cl_test

lambdas <- 10^seq(2, -3, by = -.1)

# Setting alpha = 1 implements lasso regression
lasso_reg <- cv.glmnet(x, y_train, alpha = 1, lambda = lambdas, standardize = TRUE, nfolds = 25)

# Best 
lambda_best <- lasso_reg$lambda.min 
lambda_best


lasso_model <- glmnet(x, y_train, alpha = 1, lambda = lambda_best, standardize = TRUE)

# Compute R^2 from true and predicted values
eval_results <- function(true, predicted, df) {
  SSE <- sum((predicted - true)^2)
  SST <- sum((true - mean(true))^2)
  R_square <- 1 - SSE / SST
  RMSE = sqrt(SSE/nrow(df))
  
  
  # Model performance metrics
  data.frame(
    RMSE = RMSE,
    Rsquare = R_square
  )  
}
predictions_train <- predict(lasso_model, s = lambda_best, newx = x)
eval_results(y_train, predictions_train, scaled_train)

predictions_test <- predict(lasso_model, s = lambda_best, newx = x_test)
eval_results(y_test, predictions_test, scaled_test)

# TRAIN
# RMSE    
# 4.980063
# Rsquare
# 0.4429111

# TEST
# RMSE    
# 5.12923 
# Rsquare
# 0.4209481

##############################
###Elastic Net Regression #### 
##############################
install.packages("repr")
library(repr)

# Set training control
train_cont <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 5,
                           search = "random",
                           verboseIter = TRUE)

# Train the model
elastic_reg <- train(review_scores_rating~.,
                     data = training,
                     method = "glmnet",
                     preProcess = c("center", "scale"),
                     tuneLength = 10,
                     trControl = train_cont)


# Best tuning parameter
elastic_reg$bestTune

x = as.matrix(train_dummies)
y_train = cl

x_test = as.matrix(test_dummies)
y_test = cl_test

# Make predictions on training set
predictions_train <- predict(elastic_reg, x)
eval_results(y_train, predictions_train, training) 

# Make predictions on test set
predictions_test <- predict(elastic_reg, x_test)
eval_results(y_test, predictions_test, test)

#TRAINING
# RMSE   
# 5.006063
# Rsquare
# 0.4370789

# TEST
# RMSE    
# 5.145082 
# Rsquare
# 0.4173635


SVM
library(e1071)
library(raster)
library(rgeos)
model_svm = svm(review_scores_rating ~review_scores_value+ review_scores_communication+
                host_is_superhost+ host_total_listings_count+ price+
                number_of_reviews+ privateroom+ accommodates+ is_apartment+ review_scores_checkin+ minimum_nights+ lock_on_bedroom_door+
                host_response_rate+ pool+ availability_365+ maximum_nights+ hollywood_neighbourhood+ loft+
                bathrooms+ review_scores_location+ recent_review+ reviews_per_month+guesthouse+santa_monica_neighbourhood+
                venice_neighbourhood+elevator_in_building, data = training)



#model_1
pred_m1= predict(model_svm, training)


#check performance
R2(pred_m1,training$review_scores_rating,form="traditional")
MAE(pred_m1,training$review_scores_rating)
mltools::mse(pred_m1,training$review_scores_rating)
RMSE(pred_m1,training$review_scores_rating)


#model_test
pred_m1_t= predict(model_svm, test)

#check performance
R2(pred_m1_t,test$review_scores_rating,form="traditional")
MAE(pred_m1_t,test$review_scores_rating)
mltools::mse(pred_m1_t,test$review_scores_rating)
RMSE(pred_m1_t,test$review_scores_rating)



#tune the model
svm_tune_1 <- svm(review_scores_rating ~ . ,
                  data = training,
                  cost = 15,
                  elsilon=0.1)
summary(svm_tune_1)


#predict model tuned
pred_m2= predict(svm_tune_1, training)

R2(pred_m2,training$review_scores_rating,form="traditional")
MAE(pred_m2,training$review_scores_rating)
mltools::mse(pred_m2,training$review_scores_rating)
RMSE(pred_m2,training$review_scores_rating)
#tune 1 on training
#R2:0.7776621#MAE:1.685361#MSE:9.898256#RMSE:3.146149
svm_tune_1 <- svm(review_scores_rating ~ . ,
                  data = training,
                  cost = 15,
                  elsilon=0.1)


pred_m2= predict(svm_tune_1, training)

R2(pred_m2,training$review_scores_rating,form="traditional")
MAE(pred_m2,training$review_scores_rating)
mltools::mse(pred_m2,training$review_scores_rating)
RMSE(pred_m2,training$review_scores_rating)

#tune 1 on test
#R2:0.5343584#MAE:2.766486#MSE:21.15625#RMSE:4.599592
pred_m2_t= predict(svm_tune_1, test)

R2(pred_m2_t,test$review_scores_rating,form="traditional")
MAE(pred_m2_t,test$review_scores_rating)
mltools::mse(pred_m2_t,test$review_scores_rating)
RMSE(pred_m2_t,test$review_scores_rating)


#tune 2

svm_tune_2<- svm(review_scores_rating ~ . ,
                 data = training,
                 cost = 10,
                 elsilon=0.1)
#tune 2 on train
#R2:0.7620401#MAE:1.766324#MSE: 10.59373#RMSE:3.254801
pred_m3= predict(svm_tune_2, training)

R2(pred_m3,training$review_scores_rating,form="traditional")
MAE(pred_m3,training$review_scores_rating)
mltools::mse(pred_m3,training$review_scores_rating)
RMSE(pred_m3,training$review_scores_rating)

#tune 2 on test
#R2:0.5466223#MAE:2.720335#MSE:20.59904#RMSE:4.538617
pred_m3_t= predict(svm_tune_2, test)

R2(pred_m3_t,test$review_scores_rating,form="traditional")
MAE(pred_m3_t,test$review_scores_rating)
mltools::mse(pred_m3_t,test$review_scores_rating)
RMSE(pred_m3_t,test$review_scores_rating)

#tune 3
svm_tune_3<- svm(review_scores_rating ~ . ,
                 data = training,
                 cost = 5,
                 elsilon=0.1)

#tune 3 on train
#R2:0.7346685#MAE:1.907383#MSE:11.81228#RMSE:3.4369
pred_m4= predict(svm_tune_3, training)

R2(pred_m4,training$review_scores_rating,form="traditional")
MAE(pred_m4,training$review_scores_rating)
mltools::mse(pred_m4,training$review_scores_rating)
RMSE(pred_m4,training$review_scores_rating)

#tune 3 on test
#R2:0.563347#MAE:2.656166#MSE:19.83916#RMSE: 4.454117
pred_m4_t= predict(svm_tune_3, test)

R2(pred_m4_t,test$review_scores_rating,form="traditional")
MAE(pred_m4_t,test$review_scores_rating)
mltools::mse(pred_m4_t,test$review_scores_rating)
RMSE(pred_m4_t,test$review_scores_rating)

Regression Tree 
#######################
### Regression Tree ### 
#######################

library(rpart) #for fitting decision trees
library(rpart.plot) #for plotting decision trees

# set.seed(1)
# train_rows <- sample(nrow(training),.7*nrow(training))
data_train <- training
data_valid <- test

tree <- rpart(review_scores_rating ~ ., data=data_train, control=rpart.control(cp=.0001))

#view results
printcp(tree)

#identify best cp value to use
best <- tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"]
#produce a pruned tree based on the best cp value
pruned_tree <- prune(tree, cp=best)

#use pruned tree to predict salary of this player
pred <- predict(pruned_tree, newdata=data_valid)
train_pred <-predict(pruned_tree, newdata=data_train)
library(Metrics)

rsq <- function(x, y) summary(lm(y~x))$r.squared
rmse(pred, data_valid$review_scores_rating)
MAE(pred, data_valid$review_scores_rating)
mse(pred, data_valid$review_scores_rating)
rsq(pred, data_valid$review_scores_rating)

rmse(train_pred, data_train$review_scores_rating)
MAE(train_pred, data_train$review_scores_rating)
mse(train_pred, data_train$review_scores_rating)
rsq(train_pred, data_train$review_scores_rating)

Training: R2: 0.5669277, MAE: 2.826266, MSE: 19.68255, RMSE: 4.436502
Testing: R2: 0.5843472, MAE: 2.803829, MSE: 18.50444, RMSE: 4.301678


Random Forest
library(randomForest)

rffit <- randomForest(review_scores_rating ~    review_scores_value  +  review_scores_communication  +
                       host_is_superhost  +  host_total_listings_count  +  price  +
                       number_of_reviews  +  privateroom  +  accommodates  +  is_apartment  +  review_scores_checkin  +  minimum_nights  +  lock_on_bedroom_door  +
                       host_response_rate  +  pool  +  availability_365  +  maximum_nights  +  hollywood_neighbourhood  +  loft  +
                       bathrooms  +  review_scores_location  +  recent_review  +  reviews_per_month  + guesthouse  + santa_monica_neighbourhood  +
                       venice_neighbourhood  + elevator_in_building , data = training, importance = TRUE, na.action=na.omit, ntree = 50)


plot(rffit)
print(rffit)
varImpPlot(rffit)
#predict on the training data for training dataset
predict_train_rf=predict(rffit, training)

#predict on the training data for test dataset
predict_test_rf=predict(rffit, test)


#R square, MAE, MSE, RMSE-training
R2(predict_train_rf,training$review_scores_rating,form="traditional")
MAE(predict_train_rf,training$review_scores_rating)
mltools::mse(predict_train_rf,training$review_scores_rating)
#MSE(predict_train_rf,training$review_scores_rating)
RMSE(predict_train_rf,training$review_scores_rating)

#R square, MAE, MSE, RMSE-test
R2(predict_test_rf,test$review_scores_rating,form="traditional")
MAE(predict_test_rf,test$review_scores_rating)
mltools::mse(predict_test_rf,test$review_scores_rating)
#MSE(predict_train_rf,training$review_scores_rating)
RMSE(predict_test_rf,test$review_scores_rating)

Gradient Boosting Machine (GBM)
#######################
###Gradient Boosting Machine (GBM) ### 
#######################
set.seed(13343)
trControl = trainControl(method="cv",number=5)
tuneGrid = expand.grid(n.trees = 500, #500 notes -branches 
                       interaction.depth = c(3), # 3 layers 
                       shrinkage = (1:100)*0.001, # 1-100 ways, every way x 0.001. = 0.001 runs to 0.1 
                       n.minobsinnode=c(10,15)) #10 or 15 the rial of a branch each branch least have 10 or 15 data points 

#run the trainning model into cvmodel
garbage = capture.output(cvModel <- train(review_scores_rating~.,    #avoid the review too messy
                                          data=training,
                                          method="gbm",
                                          trControl=trControl, 
                                          tuneGrid=tuneGrid))  

#######

set.seed(13343)
cvboost = gbm(review_scores_rating~.,
              data=training,
              distribution="gaussian",
              n.trees=500,
              interaction.depth=cvModel$bestTune$interaction.depth,   #call out the best parameter of cvmodel by function bestTune 
              shrinkage=cvModel$bestTune$shrinkage,
              n.minobsinnode = cvModel$bestTune$n.minobsinnode)

#know which is the best parameter
cvModel$bestTune$interaction.depth
cvModel$bestTune$shrinkage
cvModel$bestTune$n.minobsinnode

#Now we can predict
pred_train = predict(cvboost, n.trees=500)
rmse_train_cv_boost = sqrt(mean((pred_train - training$review_scores_rating)^2)); rmse_train_cv_boost

R2(pred_train,training$review_scores_rating,form="traditional")
MAE(pred_train,training$review_scores_rating)
mltools::mse(pred_train,training$review_scores_rating)

pred = predict(cvboost, newdata = test, n.trees = 500)
rmse_cv_boost = sqrt(mean((pred - test$review_scores_rating)^2)); rmse_cv_boost
R2(pred,test$review_scores_rating,form="traditional")
MAE(pred,test$review_scores_rating)
mltools::mse(pred,test$review_scores_rating)


#############GBM ways 2############################
#GB boost
cvboost_1 = gbm(review_scores_rating~.,data=training,
                distribution = "gaussian", n.trees = 100, shrinkage = 0.1,
                interaction.depth = 3, bag.fraction = 0.5, train.fraction = 0.5,
                n.minobsinnode = 10, cv.folds = 5, keep.data = TRUE,
                verbose = FALSE, n.cores = 1)

# Check performance using the out-of-bag (OOB) error; the OOB error typically
# underestimates the optimal number of iterations
best.iter <- gbm.perf(cvboost_1, method = "OOB")
print(best.iter)

#make a prediction on training
pre_gbm <- predict(cvboost_1, newdata = training, n.trees = best.iter, type = "link")

#performance
R2(pre_gbm,training$review_scores_rating,form="traditional") 
MAE(pre_gbm,training$review_scores_rating)
mltools::mse(pre_gbm,training$review_scores_rating)
RMSE(pre_gbm,training$review_scores_rating)

#predict on test
pre_gbm_t <- predict(cvboost_1, newdata = test, n.trees = best.iter, type = "link")

#performance
R2(pre_gbm_t,test$review_scores_rating,form="traditional")
MAE(pre_gbm_t,test$review_scores_rating)
mltools::mse(pre_gbm_t,test$review_scores_rating)
RMSE(pre_gbm_t,test$review_scores_rating)

